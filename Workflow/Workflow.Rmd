---
author: "Hector Roux de BÃ©zieux"
date: '`r format(Sys.time(), "%d %B , %Y")`'
title: 'Dune workflow on the baron dataset'
output:
  html_document:
    toc: true
    toc_float: TRUE
    toc_depth: 2
    number_sections: true
    code_download: TRUE
---

```{r load packages, include=F}
library(knitr)
opts_chunk$set(
  fig.pos = "!h", out.extra = "", warning = F, message = F,
  fig.align = "center"
)
NCORES <- 2
```

# Load data

We download the data from segerstolpe et al, hosted [here]

```{r}
suppressPackageStartupMessages({
  library(SingleCellExperiment)
  library(stringr)
  library(scRNAseq)
})
sce <- BaronPancreasData()
# We select the largest batch to avoid pre-processing issues
# sce <- sce[, sce$donor == "GSM2230759"]
filt <- rowSums(counts(sce) >= 2) >= 10
sce <- sce[filt, ]
sce
rm(filt)
```

# Pre-processing

The dataset can be normalized using SCVI 

```{r}
suppressPackageStartupMessages({
  library(Seurat)
})
pre_process_time <- system.time({
  se <- CreateSeuratObject(counts = counts(sce),
                           min.cells = 0,
                           min.features = 0,
                           project = "de")
  se <- AddMetaData(se, as.data.frame(colData(sce)))
  se <- NormalizeData(se, verbose = FALSE)
  se <- FindVariableFeatures(se, selection.method = 'vst', nfeatures = 4000,
                             verbose = FALSE)
  se <- se[VariableFeatures(se), ]
  se <- ScaleData(object = se, vars.to.regress = c("nCount_RNA", "donor"))
  sce <- as.SingleCellExperiment(se)
})
```

```{r, warning=FALSE}
suppressPackageStartupMessages({
  library(reticulate)
})
use_python("/usr/local/bin/python3")
scvi <- import("scvi")
anndata <- import("anndata")
np <- import("numpy")
sc <- import("scanpy")
scvi_time <- system.time({
  adata <- anndata$AnnData(X = as.sparse(t(counts(sce))),
                           obs = data.frame(cells = colnames(sce),
                                            batch = sce$donor))
  scvi$data$setup_anndata(adata, batch_key = "batch")
  model <- scvi$model$SCVI(adata)
  model$train(n_epochs = as.integer(50), n_epochs_kl_warmup = as.integer(20))
})
```

We can visualize the data using the labels from the original publication

```{r}
library(scater)
reducedDim(sce, "scvi") <- model$get_latent_representation()
denoised <- t(model$get_normalized_expression(adata, library_size = 10e4))
dimnames(denoised) <- dimnames(counts(sce))
assay(sce, "denoised") <- log1p(denoised)
sce <- runTSNE(sce, dimred = "scvi")
plotTSNE(sce, colour_by = "label")
plotTSNE(sce, colour_by = "donor")
```

# Creating inputs to Dune
## sc3

```{r, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(SC3))
sc3_time <- system.time({
  sce_sc3 <- sce
  logcounts(sce_sc3) <- assay(sce, "denoised")
  rowData(sce_sc3)$feature_symbol <- rownames(sce_sc3)
  counts(sce_sc3) <- as.matrix(counts(sce_sc3))
  logcounts(sce_sc3) <- as.matrix(logcounts(sce_sc3))
  sce_sc3 <- sc3_estimate_k(sce_sc3)
  K <- metadata(sce_sc3)$sc3$k_estimation
  # Note: with R >= 4.0, RStudio and Mac OS, this can fails. 
  # A workaround is running 
  # parallel:::setDefaultClusterOptions(setup_strategy = "sequential")
  sce_sc3 <- sc3(sce_sc3, ks = K, n_cores = NCORES, rand_seed = 786907,
                 svm_num_cells = round(.1 * ncol(sce)))
  sce_sc3 <- sc3_run_svm(sce_sc3, ks = K)    
  sce$SC3 <- colData(sce_sc3)[, paste0("sc3_", K, "_clusters")] %>% as.factor()
})
plotTSNE(sce, colour_by = "SC3")
```

## Seurat 

```{r}
seurat_time <- system.time({
  se <- RunPCA(se, verbose = FALSE)
  se <- FindNeighbors(se, verbose = FALSE)
  se <- FindClusters(object = se, verbose = FALSE)
  sce$seurat <- Idents(se)
})
plotTSNE(sce, colour_by = "seurat")
```

## Seurat with SCVI

```{r}
seurat_scvi_time <- system.time({
  seu <- as.Seurat(x = sce, counts = "counts", data = "counts")
  seu <- FindNeighbors(seu, reduction = "scvi", verbose = FALSE)
  seu <- FindClusters(object = seu, verbose = FALSE)
  sce$seurat_scvi <- Idents(seu)
})
plotTSNE(sce, colour_by = "seurat_scvi")
```

# Running Dune

```{r}
library(Dune)
df <- colData(sce)[, c("SC3", "seurat", "seurat_scvi")] %>%
  as.matrix()
dune_time <- system.time(
  merger <- Dune(clusMat = df, BPPARAM = BPPARAM, metric = "NMI")
)
```

```{r}
plotPrePost(merger)
NMItrend(merger)
```

```{r}
plotNMIs(merger$initialMat)
plotNMIs(merger$currentMat)
```

# Picking the final clustering result to use
## Visual pick

```{r}
sce$seurat_Final <- as.factor(merger$currentMat$seurat)
plotTSNE(sce, colour_by = "seurat_Final")
```

```{r}
sce$seurat_scvi_Final <- as.factor(merger$currentMat$seurat_scvi)
plotTSNE(sce, colour_by = "seurat_scvi_Final")
```

```{r}
sce$SC3_Final <- as.factor(merger$currentMat$SC3)
plotTSNE(sce, colour_by = "SC3_Final")
```

## Picking based on sihouette

```{r}
library(cluster)
dist_mat <- dist(as.matrix(reducedDim(sce, "scvi")))
sils <- lapply(merger$currentMat %>% as.data.frame, function(label){
  silhouette(label, dist = dist_mat)[,3] %>%  mean()
}) %>% unlist()
sils
```

# Runtimes

```{r}
times <- c(pre_process_time[1],
           scvi_time[1],
           sc3_time[1],
           seurat_time[1],
           seurat_scvi_time[1],
           dune_time[1])
names(times) <- c("Pre-Process",
                  "SCVI",
                  "Sc3",
                  "Seurat",
                  "Seurat after SCVI",
                  "Dune")
df <- data.frame(times = times,
                 Name = factor(names(times), levels = names(times)))
ggplot(df, aes(x = Name, y = times, fill = Name)) +
  geom_col() +
  theme_classic() +
  labs(x = "Step", y = "Time (second)") +
  scale_color_brewer(palette = "Dark2") +
  scale_y_log10()
```